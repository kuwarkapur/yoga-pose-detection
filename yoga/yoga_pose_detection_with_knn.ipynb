{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries used in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import array\n",
    "import os\n",
    "import argparse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect pose on the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BODY_PARTS = { \"Nose\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n",
    "               \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n",
    "               \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"REye\": 14,\n",
    "               \"LEye\": 15, \"REar\": 16, \"LEar\": 17, \"Background\": 18 }\n",
    "\n",
    "POSE_PAIRS = [ [\"Neck\", \"RShoulder\"], [\"Neck\", \"LShoulder\"], [\"RShoulder\", \"RElbow\"],\n",
    "               [\"RElbow\", \"RWrist\"], [\"LShoulder\", \"LElbow\"], [\"LElbow\", \"LWrist\"],\n",
    "               [\"Neck\", \"RHip\"], [\"RHip\", \"RKnee\"], [\"RKnee\", \"RAnkle\"], [\"Neck\", \"LHip\"],\n",
    "               [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"], [\"Neck\", \"Nose\"], [\"Nose\", \"REye\"],\n",
    "               [\"REye\", \"REar\"], [\"Nose\", \"LEye\"], [\"LEye\", \"LEar\"] ]\n",
    "\n",
    "width = 368\n",
    "height = 368\n",
    "inWidth = width\n",
    "inHeight = height\n",
    "\n",
    "net = cv.dnn.readNetFromTensorflow(\"graph_opt.pb\")\n",
    "thr = 0.2\n",
    "\n",
    "def poseDetect(frame):\n",
    "    frameWidth = frame.shape[1]\n",
    "    frameHeight = frame.shape[0]\n",
    "    \n",
    "    net.setInput(cv.dnn.blobFromImage(frame, 1.0, (inWidth, inHeight), (127.5, 127.5, 127.5), swapRB=True, crop=False))\n",
    "    out = net.forward()\n",
    "    out = out[:, :19, :, :]  \n",
    "\n",
    "    assert(len(BODY_PARTS) == out.shape[1])\n",
    "\n",
    "    points = []\n",
    "    for i in range(len(BODY_PARTS)):\n",
    "        \n",
    "        heatMap = out[0, i, :, :]\n",
    "\n",
    "        _, conf, _, point = cv.minMaxLoc(heatMap)\n",
    "        x = (frameWidth * point[0]) / out.shape[3]\n",
    "        y = (frameHeight * point[1]) / out.shape[2]\n",
    "        points.append((int(x), int(y)) if conf > thr else None)\n",
    "\n",
    "    for pair in POSE_PAIRS:\n",
    "        partFrom = pair[0]\n",
    "        partTo = pair[1]\n",
    "        assert(partFrom in BODY_PARTS)\n",
    "        assert(partTo in BODY_PARTS)\n",
    "\n",
    "        idFrom = BODY_PARTS[partFrom]\n",
    "        idTo = BODY_PARTS[partTo]\n",
    "\n",
    "        if points[idFrom] and points[idTo]:\n",
    "            cv.line(frame, points[idFrom], points[idTo], (0, 255, 0), 3)\n",
    "            cv.ellipse(frame, points[idFrom], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n",
    "            cv.ellipse(frame, points[idTo], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n",
    "\n",
    "    t, _ = net.getPerfProfile()\n",
    "\n",
    "    return frame "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we can get the labels and features of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = ['downdog', 'goddess', 'plank', 'tree', 'warrior2']\n",
    "train_feature=[]\n",
    "test_feature=[]\n",
    "train_labels = []\n",
    "test_labels=[]\n",
    "def create_train(DIR,label,feature):\n",
    "    for person in poses:\n",
    "        path = os.path.join(DIR, person)\n",
    "        for img in os.listdir(path):\n",
    "            img_path = os.path.join(path,img)\n",
    "            img_array = cv.imread(img_path)\n",
    "            if img_array is None:\n",
    "                continue \n",
    "            else:\n",
    "                frame = poseDetect(img_array)\n",
    "                frame_new=cv.imread(img_path)\n",
    "                if(frame.shape[2]==frame_new.shape[2]):\n",
    "                    frame_diff=frame-frame_new\n",
    "                    feature.append(frame_diff)\n",
    "                    label.append(person)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-821c9f00a191>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features_train=np.array(train_feature)\n"
     ]
    }
   ],
   "source": [
    "pose=create_train(r\"C:\\Users\\ankit\\Documents\\Python Scripts\\Face Recognition\\Intern Project\\Yoga Train Pose\",train_labels,train_feature)\n",
    "features_train=np.array(train_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-d32712b7e4b1>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features_test=np.array(test_feature)\n"
     ]
    }
   ],
   "source": [
    "test_pose = create_train(r\"C:\\Users\\ankit\\Documents\\Python Scripts\\Face Recognition\\Intern Project\\Yoga Test Pose\",test_labels,test_feature)\n",
    "features_test=np.array(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train.reshape(len(train_labels),1)\n",
    "features_test.reshape(len(test_labels),1)\n",
    "\n",
    "train_data=pd.DataFrame(features_train ,columns=['tr_feature'])\n",
    "train_labels_data=pd.DataFrame(train_labels ,columns=['tr_label'])\n",
    "\n",
    "test_data=pd.DataFrame(features_test ,columns=['te_feature'])\n",
    "test_labels_data=pd.DataFrame(test_labels ,columns=['te_label'])\n",
    "\n",
    "for i in range(len(train_data['tr_feature'])):\n",
    "    train_data['tr_feature'][i]=train_data['tr_feature'][i].flatten()\n",
    "for i in range(len(test_data['te_feature'])):\n",
    "    test_data['te_feature'][i]=test_data['te_feature'][i].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=LabelEncoder()\n",
    "labels_train=label.fit_transform(train_labels_data['tr_label'])\n",
    "labels_test=label.fit_transform(test_labels_data['te_label']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=[]\n",
    "test=[]\n",
    "for i in range(len(train_data['tr_feature'])):\n",
    "     train.append(train_data ['tr_feature'][i].std())\n",
    "for i in range(len(test_data['te_feature'])):\n",
    "     test.append(test_data['te_feature'][i].std())\n",
    "        \n",
    "train=np.array(train)\n",
    "train=np.reshape(train,(len(labels_train),1))\n",
    "test=np.array(test)\n",
    "test=np.reshape(test,(len(labels_test),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.49      0.43        97\n",
      "           1       0.43      0.16      0.24        80\n",
      "           2       0.38      0.34      0.36       115\n",
      "           3       0.26      0.12      0.16        69\n",
      "           4       0.31      0.50      0.38       109\n",
      "\n",
      "    accuracy                           0.35       470\n",
      "   macro avg       0.35      0.32      0.31       470\n",
      "weighted avg       0.35      0.35      0.33       470\n",
      "\n",
      "[[48  0 28  3 18]\n",
      " [12 13  9  3 43]\n",
      " [39  2 39  6 29]\n",
      " [10  6 11  8 34]\n",
      " [19  9 15 11 55]]\n"
     ]
    }
   ],
   "source": [
    "rfc=RandomForestClassifier(n_estimators=300,criterion='entropy',\n",
    "                             max_features='sqrt',min_samples_leaf=10,random_state=100)\n",
    "rfc.fit(train,labels_train)\n",
    "predict=rfc.predict(test)\n",
    "print(classification_report(labels_test,predict))\n",
    "print(confusion_matrix(labels_test,predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.79      0.59       229\n",
      "           1       0.57      0.32      0.41       147\n",
      "           2       0.46      0.30      0.36       239\n",
      "           3       0.51      0.17      0.25       151\n",
      "           4       0.47      0.67      0.56       242\n",
      "\n",
      "    accuracy                           0.48      1008\n",
      "   macro avg       0.50      0.45      0.43      1008\n",
      "weighted avg       0.49      0.48      0.45      1008\n",
      "\n",
      "[[180   1  24   2  22]\n",
      " [ 29  47  16   7  48]\n",
      " [118   1  71   8  41]\n",
      " [ 21  18  17  25  70]\n",
      " [ 29  15  28   7 163]]\n"
     ]
    }
   ],
   "source": [
    "rfc.fit(train,labels_train)\n",
    "predict=rfc.predict(train)\n",
    "print(classification_report(labels_train,predict))\n",
    "print(confusion_matrix(labels_train,predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.53      0.46        97\n",
      "           1       0.30      0.24      0.27        80\n",
      "           2       0.44      0.32      0.37       115\n",
      "           3       0.19      0.25      0.21        69\n",
      "           4       0.26      0.26      0.26       109\n",
      "\n",
      "    accuracy                           0.32       470\n",
      "   macro avg       0.32      0.32      0.31       470\n",
      "weighted avg       0.33      0.32      0.32       470\n",
      "\n",
      "[[51  4 13 13 16]\n",
      " [11 19 10 19 21]\n",
      " [33 11 37 17 17]\n",
      " [11 13  4 17 24]\n",
      " [20 16 21 24 28]]\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(train,labels_train)\n",
    "predict_knn=knn.predict(test)\n",
    "print(classification_report(labels_test,predict_knn))\n",
    "print(confusion_matrix(labels_test,predict_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75       229\n",
      "           1       1.00      0.88      0.94       147\n",
      "           2       1.00      0.59      0.74       239\n",
      "           3       1.00      0.89      0.94       151\n",
      "           4       1.00      0.92      0.96       242\n",
      "\n",
      "    accuracy                           0.85      1008\n",
      "   macro avg       0.92      0.86      0.87      1008\n",
      "weighted avg       0.91      0.85      0.85      1008\n",
      "\n",
      "[[229   0   0   0   0]\n",
      " [ 17 130   0   0   0]\n",
      " [ 99   0 140   0   0]\n",
      " [ 17   0   0 134   0]\n",
      " [ 19   0   0   0 223]]\n"
     ]
    }
   ],
   "source": [
    "knn.fit(train,labels_train)\n",
    "predict_rfc=knn.predict(train)\n",
    "print(classification_report(labels_train,predict_rfc))\n",
    "print(confusion_matrix(labels_train,predict_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
